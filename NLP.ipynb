{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oguzhankoc55/Text-Smilarity-NLP/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metin benzerligi \n",
        "Nlp dersinde verilen ara dönem projesi yerine geçen proje için oluşturulan belge.Bu projede metin benzerligi yöntemlerini kullanarak elimizdeki veriler ile hakem ataması denemeleri yaptık."
      ],
      "metadata": {
        "id": "yGaeUC5UIwqq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verilerin Yüklenmesi\n",
        "Veriler drive üzerinde bulunan adresleri belirlenir ve bu adreslerdeki veriler çekilir."
      ],
      "metadata": {
        "id": "PLwHAvArJrVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "import re\n",
        "from gensim import utils\n",
        "from gensim.models.doc2vec import LabeledSentence\n",
        "from gensim.models import Doc2Vec\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "metadata": {
        "id": "RoPZqx43KcQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_data(path):\n",
        "  veriler = []\n",
        "  pdfler = os.listdir(path)\n",
        "  for pdf in pdfler:\n",
        "    try:\n",
        "        veri= {\n",
        "            \"isim\":\"\",\n",
        "        }\n",
        "        veri.update({\"isim\" : pdf})\n",
        "        dosya = open(path+pdf,\"r\")\n",
        "        for metin in dosya:\n",
        "            veri.update({\"metin\":metin})\n",
        "        \n",
        "        dosya.close()\n",
        "        veriler.append(veri)\n",
        "    except:\n",
        "        print( \"hata\")\n",
        "  return veriler"
      ],
      "metadata": {
        "id": "8asCTxQnKM9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def refactor(path):\n",
        "  results = []\n",
        "  dosya = open(path,\"r\")\n",
        "  for metin in dosya:\n",
        "    veri= {\n",
        "            \"isim\":\"\",\n",
        "        }\n",
        "    result = metin.replace(\"\\n\",\"\").split(\"\\t\")\n",
        "    _List = []\n",
        "    for i in range(len(result)):\n",
        "      if(i == 0 ):\n",
        "        veri.update({\"isim\" : result[i]})\n",
        "      else:\n",
        "        _List.append({str(i):result[i]})\n",
        "    veri.update({\"revievers\":_List})  \n",
        "    results.append(veri)\n",
        "\n",
        "  return results"
      ],
      "metadata": {
        "id": "T1eKxEacmiQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#adding datasets\n",
        "path_manu= \"/content/drive/MyDrive/kodlamalar/okul_projesi/nlp/Dataset/manuscripts/\"\n",
        "path_revi= \"/content/drive/MyDrive/kodlamalar/okul_projesi/nlp/Dataset/reviewers/\"\n",
        "path_ground = \"/content/drive/MyDrive/kodlamalar/okul_projesi/nlp/Dataset/groundturth.txt\"\n",
        "\n",
        "manuscripts_veriler = make_data(path_manu)\n",
        "revievers_veriler = make_data(path_revi)\n",
        "groundturth_veriler = refactor(path_ground)"
      ],
      "metadata": {
        "id": "2iWASiGxHsEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "Wb3lTk1lbGkW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### noktalama işaretleri ve sayıların atılması"
      ],
      "metadata": {
        "id": "C1V7YNm0vT3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def To_lower(veriler):\n",
        "  for i in range(len(veriler)):\n",
        "    veriler[i][\"metin\"] = veriler[i][\"metin\"].lower()\n",
        "    veriler[i][\"metin\"] = veriler[i][\"metin\"].replace(\"\\n\",\" \").replace(\"\\t\",\" \")\n",
        "    veriler[i][\"metin\"] = re.sub(r'[^a-zA-Z\\s]', ' ', veriler[i][\"metin\"])\n",
        "  return veriler"
      ],
      "metadata": {
        "id": "snqRH7KscRTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "manuscripts_veriler=To_lower(manuscripts_veriler)\n",
        "revievers_veriler=To_lower(revievers_veriler)"
      ],
      "metadata": {
        "id": "tVULQNe7cLIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### stopwordslerin çıkarılması"
      ],
      "metadata": {
        "id": "-NWZS0CA11QH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords') \n",
        "stop_words =  set(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8Pymxh_vckd",
        "outputId": "80b9cf30-46bd-4af1-f90c-d30fa7294e4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def del_stopWords(veriler):\n",
        "  for i in range(len(veriler)):\n",
        "    veriler[i][\"metin\"]  = \" \".join([c for c in veriler[i][\"metin\"].split() \n",
        "    if c not in stop_words if len(c)>1])\n",
        "  return veriler"
      ],
      "metadata": {
        "id": "JWuMgT78vqEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "manuscripts_veriler = del_stopWords(manuscripts_veriler)\n",
        "revievers_veriler= del_stopWords(revievers_veriler)"
      ],
      "metadata": {
        "id": "f4qn40L-xNYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = nltk.porter.PorterStemmer()"
      ],
      "metadata": {
        "id": "k1GUoYUU39rV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metin = ' '.join([stemmer.stem(word) for word in manuscripts_veriler[1][\"metin\"].split()])\n",
        "metin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "mXL3PwKV4qt9",
        "outputId": "df177c99-e830-4a3a-9670-2beb66240f0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'higher spin black hole soft hair construct new set boundari condit higher spin graviti inspir recent soft heisenberg hair propos gener rel onthre dimension anti de sitter asymptot symmetri algebra consist aset affin hat current algebra associ canon chargesgener higher spin soft hair focu first spin case thenextend main result spin mani resembl spin result gener asymptot algebra natur emerg fromcomposit oper hat charg twist sugawaraconstruct boundari condit ensur regular euclideansolut space independ valu charg solut wecal higher spin black flower stationari necessarilyspher symmetr final deriv entropi higher spin blackflow find branch continu connect btzblack hole depend affin pure gravit zero mode use map algebra current recov well known express forhigh spin entropi also address higher spin black flower metricform achiev full consist previou result'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "manuscripts_veriler[1][\"metin\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "CuTFUCg83HrX",
        "outputId": "abc83ddb-2b20-42c6-f6bf-12bd14db278d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'higher spin black holes soft hair construct new set boundary conditions higher spin gravity inspired recent soft heisenberg hair proposal general relativity onthree dimensional anti de sitter asymptotic symmetry algebra consists aset affine hat current algebras associated canonical chargesgenerate higher spin soft hair focus first spin case thenextend main results spin many resemble spin results generators asymptotic algebra naturally emerge fromcomposite operators hat charges twisted sugawaraconstruction boundary conditions ensure regularity euclideansolutions space independently values charges solutions wecall higher spin black flowers stationary necessarilyspherically symmetric finally derive entropy higher spin blackflowers find branch continuously connected btzblack hole depends affine purely gravitational zero modes using map algebra currents recover well known expressions forhigher spin entropy also address higher spin black flowers metricformalism achieve full consistency previous results'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    }
  ]
}